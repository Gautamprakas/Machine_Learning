{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cd9183-271b-4757-a786-f1b2e14c1073",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how\n",
    "can they be mitigated?\n",
    "Answer-\n",
    "Underfitting: A statistical model or a machine learning algorithm is said to have underfitting when it cannot capture the under\n",
    "lying trend of the data, i.e., it only performs well on training data but performs poorly on testing data. (It’s just like \n",
    "trying to fit undersized pants!) Underfitting destroys the accuracy of our machine learning model. Its occurrence simply means\n",
    "that our model or the algorithm does not fit the data well enough. It usually happens when we have fewer data to build an \n",
    "accurate model and also when we try to build a linear model with fewer non-linear data. In such cases, the rules of \n",
    "machine learning model are too easy and flexible to be applied to such minimal data and therefore the model will probably make\n",
    "a lot of wrong predictions. Underfitting can be avoided by using more data and also reducing the features by feature selection. \n",
    "\n",
    "In a nutshell, Underfitting refers to a model that can neither performs well on the training data nor generalize to new data.\n",
    "\n",
    "Consqunces of underfitting:Model does not prdict the correct output and the accuracy of the model is very low.\n",
    "Techniques to reduce underfitting: \n",
    "Increase model complexity\n",
    "Increase the number of features, performing feature engineering\n",
    "Remove noise from the data.\n",
    "Increase the number of epochs or increase the duration of training to get better results.\n",
    "\n",
    "Overfitting: A statistical model is said to be overfitted when the model does not make accurate predictions on testing data.\n",
    "When a model gets trained with so much data, it starts learning from the noise and inaccurate data entries in our data set. \n",
    "And when testing with test data results in High variance. Then the model does not categorize the data correctly, because of \n",
    "too many details and noise. The causes of overfitting are the non-parametric and non-linear methods because these types of\n",
    "machine learning algorithms have more freedom in building the model based on the dataset and therefore they can really build \n",
    "unrealistic models. A solution to avoid overfitting is using a linear algorithm if we have linear data or using the parameters \n",
    "like the maximal depth if we are using decision trees. \n",
    "\n",
    "In a nutshell, Overfitting is a problem where the evaluation of machine learning algorithms on training data is different from unseen data.\n",
    "\n",
    "Techniques to reduce overfitting:\n",
    "\n",
    "Increase training data.\n",
    "Reduce model complexity.\n",
    "Early stopping during the training phase (have an eye over the loss over the training period as soon as loss begins to increase stop training).\n",
    "Ridge Regularization and Lasso Regularization'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af32825-5c60-4c8f-8f08-00e31c0380b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q2: How can we reduce overfitting? Explain in brief.\n",
    "Answer-Here are some technique to reduce overfitting.\n",
    "1)Train with more data-If we can accuire a new data or more so we can train the model with more new data that have not much\n",
    "ambugity.\n",
    "2)Data augmentation-Data augmentation is a technique of artificially increasing the training set by creating modified copies\n",
    "of a dataset using existing data. It includes making minor changes to the dataset or using deep learning to generate new data points.\n",
    "3)Addition of noise to the input data-We can add some ambiguity in the data that reduce the train data accuracy of our model.\n",
    "4)Feature selection-In feature selection technique we can select the feature which highly correletated the target output and \n",
    "drop the feature which is not related to output.\n",
    "5)Cross-validation-Cross-validation is a resampling method that uses different portions of the data to test and train a model \n",
    "on different iterations.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7e2d96-bd87-4c6c-b4d8-199e52f31aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q3: Explain underfitting. List scenarios where underfitting can occur in ML.\n",
    "Answer-Underfitting-A statistical model or a machine learning algorithm is said to have underfitting when it cannot capture the under\n",
    "lying trend of the data, i.e., it only performs well on training data but performs poorly on testing data. (It’s just like \n",
    "trying to fit undersized pants!) Underfitting destroys the accuracy of our machine learning model. Its occurrence simply means\n",
    "that our model or the algorithm does not fit the data well enough. It usually happens when we have fewer data to build an \n",
    "accurate model and also when we try to build a linear model with fewer non-linear data. In such cases, the rules of \n",
    "machine learning model are too easy and flexible to be applied to such minimal data and therefore the model will probably make\n",
    "a lot of wrong predictions. Underfitting can be avoided by using more data and also reducing the features by feature selection.\n",
    "\n",
    "Reasons of underfittintg:\n",
    "1.Data used for training is not cleaned and contains noise (garbage values) in it.\n",
    "2.The model has a high bias.\n",
    "3.The size of the training dataset used is not enough.\n",
    "4.The model is too simple.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21a819c-5a35-49b6-ad61-6cdc32565ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "variance, and how do they affect model performance?\n",
    "Answer-It is important to understand prediction errors (bias and variance) when it comes to accuracy in any machine \n",
    "learning algorithm.\n",
    "Bias\n",
    "The bias is known as the difference between the prediction of the values by the ML model and the correct value. \n",
    "Being high in biasing gives a large error in training as well as testing data. Its recommended that an algorithm should\n",
    "always be low biased to avoid the problem of underfitting.\n",
    "Variance\n",
    "The variability of model prediction for a given data point which tells us spread of our data is called the variance of the \n",
    "model. The model with high variance has a very complex fit to the training data and thus is not able to fit accurately on the\n",
    "data which it hasn’t seen before. As a result, such models perform very well on training data but has high error rates on test\n",
    "data.\n",
    "Bias and variance are inversely connected. It is impossible to have an ML model with a low bias and a low variance.\n",
    "High Bias and High Varriance both will affect the model in accuracy if the model is high bias means it did't perform well\n",
    "in test data while the low bias tells the prediction on test data .\n",
    "The generalized model have low bias ans low varriance.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582d6f4-62ba-40db-904c-4e88144451fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "How can you determine whether your model is overfitting or underfitting?\n",
    "Answer-A model under fits when it is too simple with regards to the data it is trying to model.\n",
    "\n",
    "One way to detect such a situation is to use the bias-variance approach, which can be represented like this:\n",
    "\n",
    "Your model is under fitted when you have a high bias.\n",
    "Detectinfg overfitting:\n",
    "To address this, we can split our initial dataset into separate training and test subsets. This method can approximate \n",
    "how well our model will perform on new data.\n",
    "\n",
    "If our model does much better on the training set than on the test set, then we’re likely overfitting.\n",
    "\n",
    "We can determine whether a predictive model is underfitting or overfitting the training data by looking at the prediction \n",
    "error on the training data and the evaluation data. Your model is underfitting the training data when the model performs\n",
    "poorly on the training data.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843bb1b9-2ecc-4dee-905e-0431b53b5875",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "and high variance models, and how do they differ in terms of their performance?\n",
    "Answer-\n",
    "Bias:\n",
    "When an algorithm is employed in a machine learning model and it does not fit well, a phenomenon known as bias can develop.\n",
    "Bias arises in several situations.\n",
    "Varriance:\n",
    "The term \"variance\" refers to the degree of change that may be expected in the estimation of the target function as a \n",
    "result of using multiple sets of training data.\n",
    "\n",
    "Bias:The disparity between the values that were predicted and the values that were actually observed is referred to as bias\n",
    "Variance:A random variable's variance is a measure of how much it varies from the value that was predicted for it.\n",
    " \n",
    "Bias:The model is incapable of locating patterns in the dataset that it was trained on, and it produces inaccurate results\n",
    "for both seen and unseen data\n",
    "Variance:The model recognizes the majority of the dataset's patterns and can even learn from the noise or data that\n",
    "isn't vital to its operation.\n",
    "\n",
    "Ex:\n",
    "A linear machine-learning algorithm will exhibit high bias but low variance. On the other hand, a non-linear algorithm will\n",
    "exhibit low bias but high variance. Using a linear model with a data set that is non-linear will introduce bias into the model.\n",
    "In terms of perfomance the model is well neither perform in train data or test data'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae4216c-4ea5-4e06-9b43-92b8d59bcf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "some common regularization techniques and how they work.\n",
    "Answer-Regularization refers to techniques that are used to calibrate machine learning models in order to\n",
    "minimize the adjusted loss function and prevent overfitting or underfitting.\n",
    "Using Regularization, we can fit our machine learning model appropriately on a given test set and hence reduce the errors in it. \n",
    "\n",
    "Regularization Techniques \n",
    "There are two main types of regularization techniques: Ridge Regularization and Lasso Regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8741ceac-5b84-400b-a5d2-cff8ff83d900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
